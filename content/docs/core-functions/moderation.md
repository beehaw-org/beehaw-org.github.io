---
title: Moderation
weight: 25
---
# Moderation
[Comments](https://beehaw.org/post/439918?scrollToComments=true)

We think in the long term moderation is likely the most important aspect of this instance and key to ensuring this community stays a nice place. Moderation is a tricky subject and something that we don’t think any platform on the internet has managed to figure out.

Rather than try to summarize our current philosophy on moderation we’d like to focus on some issues we’ve seen (some of which we may not have an answer to yet).

As many Beeple are refugees from Reddit, some of the problems we're about to outline are likely problems you’ve seen with moderation.

## On Power Mods

Reddit has an issue with a certain type of individual being drawn towards moderation and a subset of them really ‘succeeding’ in the accumulation of moderator power. Some people like to refer to some of the most prolific individuals who moderate on the website as part of *‘the cabal’*. Some of these individuals are deeply emotionally invested in the platform in unhealthy ways or are seeking validation through their wielding of power and some of these individuals misuse it due to these factors. Some are also simply fairly regular humans who were around at the right time and place or otherwise social in the right way and ended up in their position. We’ve seen more drama than we really care to remember or waste mental bandwidth on. What’s important here, however, is that there’s a social component to this. These ‘cabals’ form because groups naturally occur and synthesize around power. This is true with nearly any community of a certain size, be it your local chapter of an international institution, your government, a meetup group, a convention you like to attend, or any other large gathering of individuals. Checks and balances of various sorts can and should be wielded to help prevent the slow corruption of power but we don’t think this is a problem we’ve managed to universally solve or that any solution doesn’t have both pros and cons. The community needs to decide what tradeoffs are appropriate for it.

Most communities self-police in some manner based on seniority. People who’ve been in a community for a long time are often seen as wise and elevated to places of power. Our elders often know a community extremely well. They can help provide context for the various factions within a community, synthesize the diverse opinions those factions represent, and can offer measured responses on the most likely outcomes or best solutions. However these elders *are not infallible* and any community needs to adapt to the changes building in said community from its amorphous organization and reorganization. People join and leave throughout a community's existence. Fresh ideas and new viewpoints can carry a community to new heights and bring important changes. New blood breeds *needed innovation* and *helps to center oppressed or unrepresented voices*. **There needs to be a balance between the old and the new to keep both sides in appropriate check.** If you focus the too much on the opinion of elders, you end up with issues of seniority and cliquey behavior. If you focus too much on the new voices, you risk the community splintering or imploding on itself from a lack of stability or trying to cater to too many conflicting voices at once.

## On Solutions to Power Mods

Solutions to ensure fair moderation often center the voices of the individuals in each community and give them the authority to govern themselves. We want this community to be able to govern itself at multiple levels. However self-governance is difficult. 

### Elections

Often people like to point to elections as a way to self-govern. Without even naming some of the issues with elections, we're sure most of you can look at existing elected governmental officials in nearly any country and easily identify at least one person who highlights issues with this process. By its very nature, an election often becomes a popularity contest, rife for abuse in a plethora of ways that humans with good social skills often use to their advantage.

### Sortition

Sortition (appointment by lot) may offset some of these problems but also has its pros and cons. Perhaps most importantly, we don’t want to burden anyone who’s not interested in moderating with that responsibility. We think people would be well served to examine the social groups which exist in their lives which aren’t governed via direct democracy and to spend a bit of time considering what model is most appropriate in each sphere of their life.

### Legitimacy

We wouldn't want to receive medical care from an individual which was elected by the vote of non-medical professionals. The same would be true of legal advice. We would like our moderators to be educated and skilled in moderating, and both elections and sortition don’t always center these values. Ultimately, we haven’t decided on a sustainable long-term solution to moderation, and have been choosing active members in communities which seem to embody or align with our ethos to elevate to a moderating position.

## Moderation at Beehaw

Problems aside, we do have some expectations for moderators at Beehaw.

### What is Expected of Community Moderators?

* Encourage and promote respectful and constructive discussions, and address any behaviour that goes against our community’s spirit to be(e) nice.
* Assist people by answering their questions, offering guidance, and helping them navigate the platform effectively, ensuring they feel heard.
* Where possible, give admins and/or your fellow active mods concerns, improvements, or insights you have from your section of our community.

### What Powers do Community Moderators Have?
We expect moderators to use these responsibly, obviously:

* The ability to remove or hide posts, comments, or other content that violate our community guidelines.
* The authority to issue warnings to users who breach our mantra, and in severe cases, temporarily suspend their accounts.

We generally encourage a compassionate approach to moderating, though. Unless someone is clearly unproductive, we encourage you as a mod to engage in constructive dialogue before banning. And if you don’t have the energy for this, you can flag a post to bring it to an admin's (or another mod’s) attention.

Additionally: blatantly misusing these or using them maliciously will be instant grounds for demotion, and in the latter case likely permanent banning from the site. Do not do that, please and thank you.

## On Content Removal

Harmful, bigoted, or generally distasteful content isn't as frequent on our site as it is elsewhere, but these do still appear enough that we sometimes get questions about why certain comments are left up. This post is meant to help you understand a bit about *how* we moderate.

As stated in our sidebar and in tons of other places on our site, Beehaw aspires to be(e) a safe, friendly, and diverse place. Because everyone who participates on Beehaw plays an important role in that mission, we stress our collective responsibility to be inclusive and interact with intention in our communities. Building this space goes deeper than how admins and mods exercise content moderation though. It's also dependent on our culture, our personal duty to the community, and - to some extent - on our community itself.

### Leaving Things up and the "Sanitized Space"

Moderation often sees us balance two things:

* (1) people being able to see community support - especially when they're used to seeing shitty behavior overtly supported, glossed over, or swept under the rug like on other sites - and;

* (2) some people's desire to see a site where they don't see unsavory comments at all (a "*sanitized space*").

We prioritize the first, and understand but generally disagree with the second when moderating Beehaw.

When browsing Beehaw, you may run across and report material that is not nice. Sometimes comments are clearly hate speech and easy to deal with, but *most* material that isn't nice is more ambiguous - it's an uninformed person who has a bad, bigoted-sounding take. As a team of admins and moderators, a *lot* of what we do is discuss what crosses the line - what should be left up and what should be removed. Nearly every removal crosses anywhere from a few to dozens of moderator eyes before action is taken (it's one of our most active chat channels). In many cases our community influences that decision. When the community puts forward a strong response against something, we might be more inclined to allow a comment we'd otherwise remove to stay. If no such response happens, we're much quicker to remove content.

Many of our users probably pay no mind to any of this. They implicitly trust us to make the right call, do not have a strong opinion on this balancing act, or agree with leaving the content alone in the first place. Some users *do* disagree with this moderation style however - and we understand why. This can feel like us betraying the promise of a safe space, brave space, or whatever you wish to call our website.[^1] For shorthand purposes and to fit the theme, we'll call this position of wanting an online space completely free of bigotry and other distasteful content a *sanitized space*.

To be clear: *a sanitized space has its place*. We are not disputing the overall utility of said spaces, and it's fine to want one. For *our purposes* however this is not possible or desirable - we do not wish Beehaw to be a sanitized space.

In a sanitized space it's really hard to know when people are acting in good faith or bad faith. The act of sanitization also necessarily assumes bad faith - painful material is removed with no discussion. For our purposes, this is a problem: without discussion we sometimes cannot tell the difference between a willful bigot and someone with good intent who is just uninformed. This assumption of bad faith also leads to a zero-sum moderation style, where people can be permanently banned for a single comment because there is no room to gauge intent. By giving space for people to ask questions (and presuming those questions are at least reasonably well intentioned), we are facilitating their growth as people - and hopefully, facilitating the growth of other people in the community too.

This is not navel gazing, either. We've already seen cases where someone changed their view because of informative comments or thoughtful pushback from our community. In one particular case someone retroactively edited their comment to say they were wrong and had learned something. We want to encourage scenarios like these! But those scenarios simply can't happen in sanitized spaces - because even the slightest doubt about whether a poster is acting in good faith should be (and often is) cause for removal.

Aggressive sanitization has other drawbacks too. It can - unfortunately - encourage a persecution complex even in cases where that's not warranted. Meaningful disagreement generally cannot happen in sanitized spaces either, and this makes it very difficult to demonstrate a community's values. By necessity, these spaces also cannot be reflective of the world we live in - which is frequently very bigoted and hateful - and that can be to their detriment. If every bigoted or questionable take is swept under the rug, there's no chance for the community to band together and show solidarity for people being marginalized or attacked.

All this is to say that a sanitized space can deter the community, collectively, from potentially beneficial dialogue. Stuff like that is part of what we want to encourage on Beehaw, and this is true even if no minds among the original participants are changed in the process. This is not a vacuum: there are also *observers* to conversations that must be considered - Beehaw users, users from other instances, and people considering joining Beehaw. For these people comment chains can be spaces for learning and they can practically *show* (rather than tell) our community's values. They can also deter bigots; people who are Just Asking Questions (often referred to as JAQing) or sealioning; or other bad-faith participants from joining at all. And they can of course save us from having to repeat ourselves.

And for what it's worth, we do recognize it's really hard to moderate the way we want to - that is, by involving some community discussion in the process - without eventually tipping over into being *too* permissive of bad behavior and creating an environment which feels aggressive or negative.

### User Responsibility

While most moderation obviously falls to us, you as a user have responsibilities in this domain too. **Ultimately: you must take some responsibility for curation of what you see on this website.** We have *thousands* of active users. It is unrealistic and unfair to expect us to moderate everyone else based purely on someone's discomfort or expectations. If you ever see any questionable, upsetting, or not nice content, please report it! Alerting us to material that might warrant discussion, even if no actions are taken, helps us to keep this place nice.

However, from a pragmatic standpoint: Beehaw is ultimately a public space - curated as it may be - and you will be exposed to content you neither agree with nor feel comfortable with as a product of that. This is perfectly fine. It is also fine to disagree with some things we allow here that you personally would not. These are normal parts of existing in public spaces with other people and using services that are not your own respectively. But that *also* means you must be willing to compromise or take personal action to protect yourself sometimes - our moderation cannot and will not guarantee a completely agreeable space for you.

From a logistical standpoint: **we simply cannot privilege your personal discomfort over anyone else's, and we cannot always cater specifically to you and what you want.** Your personal positions on right or wrong are not *inherently* more valid than someone else's when weighing most questions of how we should moderate this space. There are often plenty of people who do not feel like you that we must also consider in moderation decisions. 

Different spaces also exist for different people, and that's for a reason. If this space is not to your own personal standards, you are welcome to leave - we genuinely don't take it personally! This place is not for everyone, and we freely say so. A key selling point of federation - and part of why we're on a federated service - is that you don't have to register on our site to interact with us if you don't want to. You should exercise this option if and when you feel it necessary.

### Community-Based Moderation

Building online communities isn't a perfect science and there's no single right way to go about it. Our moderation is just one effort towards making Beehaw safe, friendly, and diverse - but it is far from the only important aspect. Community also matters here.

Moderators aren't cops, and Beehaw's communities aren't our personal court rooms. We aren't (and can't be) supreme or ideal authorities over what is and isn't acceptable speech. We can generally feel when someone isn't acting in good faith or being nice, and it's obvious to us when someone is just spewing garden-variety bigotry. But for comments where the distinction between good and bad faith is unclear, community interventions matter just as much as mod action.

What we feel as moderators doesn't always have the same weight as strong community support or opposition. Just like an individual user's sensibilities with respect to moderation aren't universal or infallible, our individual judgments as moderators are limited. That's why even when moderators haven't been able to directly engage, community responses (through comments, reports, upvotes, etc.) fill the void. If our community and our users weren't so clear about their attitudes towards certain speech, the modlog would be much more crowded. We can ban users or remove comments, but these are only small, individual actions - tools which don't have the same thrust as community culture. As things are, we're limited by Lemmy's moderation tools, which aren't (yet) built for greater scale.

Ultimately, our community building revolves around not only mod actions, e.g. to remove the worst stuff or nudge people towards being nice, but also our efforts as users to curate our experiences and enact our community ethos across Beehaw. We've seen countless examples of an outpouring of community support in reply to questionable content and we want this to happen regularly. A chorus of supportive voices often does more to demonstrate ethos than any moderator actions could or should. Ultimately we're a community, and we both want and need all of your involvement to make this space work.

---

[^1]: There are some overlapping as well as unique intentions behind terms like *safe space*, *brave space*, or *accountable space*, but they're (mostly) beyond the scope of this philosophical piece.
